{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('pathtofindspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkLab = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to the csv file including the filename: SkylineLab.csv\n"
     ]
    }
   ],
   "source": [
    "fileName = str(input(\"Enter the path to the csv file including the filename: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "    if not \".csv\" in fileName:\n",
    "        fileName += \".csv\"\n",
    "    return fileName\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkLab.read.csv(fileName, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+--------------------+\n",
      "|    Date|       Time|      Street_Address|          City_State|\n",
      "+--------+-----------+--------------------+--------------------+\n",
      "|7/1/2014| 8:27:00 PM|    622 THIRD AV ...|     M           ...|\n",
      "|7/1/2014| 9:04:00 PM|     E 77TH ST   ...|     M           ...|\n",
      "|7/1/2014|10:20:00 PM|    67 WEST PALIS...|    PALISADES PAR...|\n",
      "|7/1/2014|12:28:00 PM|    130 MIDDLE NE...|    SANDS POINT L...|\n",
      "|7/1/2014| 4:45:00 PM|    36 E 31ST ST ...|     M           ...|\n",
      "|7/1/2014| 6:15:00 PM|    120 E 16TH ST...|     M           ...|\n",
      "|7/1/2014| 8:55:00 PM|    300 FLATBUSH ...|     BK          ...|\n",
      "|7/1/2014|10:00:00 PM|    410 PARK AV  ...|     M           ...|\n",
      "|7/1/2014| 6:00:00 AM|    5 E 22ND ST  ...|     M           ...|\n",
      "|7/1/2014| 5:21:00 AM|    2249 MORRIS A...|     BX          ...|\n",
      "|7/1/2014| 6:15:00 AM|    1536 CROSBY A...|     BX          ...|\n",
      "|7/1/2014| 8:40:00 AM|    3260 PERRY AV...|     BX          ...|\n",
      "|7/1/2014|10:40:00 AM|    140 W 140TH S...|     M           ...|\n",
      "|7/1/2014| 1:03:00 PM|    17 E 102ND ST...|     M           ...|\n",
      "|7/1/2014| 3:10:00 PM|    2615 THIRD AV...|     BX          ...|\n",
      "|7/1/2014| 3:54:00 PM|    1221 JEROME A...|     BX          ...|\n",
      "|7/1/2014| 9:20:00 AM|    18718 NASHVIL...|     QU          ...|\n",
      "|7/1/2014|10:00:00 AM|    22620 FRANCIS...|     QU          ...|\n",
      "|7/1/2014|12:40:00 PM|    5229 35TH ST ...|    NEW YORK QU  ...|\n",
      "|7/1/2014| 1:40:00 PM|    622 THIRD AV ...|     M           ...|\n",
      "+--------+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizeDate(df):  #Change the format of the date\n",
    "    df = df.withColumn(\"Date\", F.regexp_replace(F.col('Date'), \"/\", \"-\"))\n",
    "    return df\n",
    "            \n",
    "df = standardizeDate(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " #If the date and time exist separately, join them in one column\n",
    "def checkIfDateExistsSeparately(df):   \n",
    "    if 'Date' in df.columns:\n",
    "        if 'Time' in df.columns:\n",
    "            df = df.withColumn('Datetime', F.concat(F.col('Date'), F.lit(' '), F.col('Time')))\n",
    "            columsToDrop = ['Date', 'Time']\n",
    "            df = df.drop(*columsToDrop)\n",
    "    else:\n",
    "        print(\"The columns date and time don't exist separately\")\n",
    "        return df\n",
    "    return df\n",
    "df = checkIfDateExistsSeparately(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTrailingAndLeadingSpaces(df):\n",
    "    for x in df.columns:\n",
    "         df = df.withColumn(x, F.trim(x))\n",
    "    return df\n",
    "df = removeTrailingAndLeadingSpaces(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createColumnsAndSelect(df):\n",
    "    df = df.withColumn(\"Source\", F.lit(\"SKYLINE\"))\n",
    "    df = df.withColumn(\"City\", F.lit(\" \"))\n",
    "    df = df.withColumn(\"State\", F.lit(\" \"))\n",
    "    df = df.select(['Datetime', 'Street_Address', 'City', 'City_State', 'State', 'Source'])\n",
    "    return df\n",
    "df = createColumnsAndSelect(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+-----------------+-----+-------+\n",
      "|            Datetime|      Street_Address|City|       City_State|State| Source|\n",
      "+--------------------+--------------------+----+-----------------+-----+-------+\n",
      "| 7-1-2014 8:27:00 PM|        622 THIRD AV|    |                M|     |SKYLINE|\n",
      "| 7-1-2014 9:04:00 PM|           E 77TH ST|    |                M|     |SKYLINE|\n",
      "|7-1-2014 10:20:00 PM|67 WEST PALISADES...|    |PALISADES PARK NJ|     |SKYLINE|\n",
      "|7-1-2014 12:28:00 PM|  130 MIDDLE NECK RD|    |   SANDS POINT LI|     |SKYLINE|\n",
      "| 7-1-2014 4:45:00 PM|        36 E 31ST ST|    |                M|     |SKYLINE|\n",
      "| 7-1-2014 6:15:00 PM|       120 E 16TH ST|    |                M|     |SKYLINE|\n",
      "| 7-1-2014 8:55:00 PM|     300 FLATBUSH AV|    |               BK|     |SKYLINE|\n",
      "|7-1-2014 10:00:00 PM|         410 PARK AV|    |                M|     |SKYLINE|\n",
      "| 7-1-2014 6:00:00 AM|         5 E 22ND ST|    |                M|     |SKYLINE|\n",
      "| 7-1-2014 5:21:00 AM|      2249 MORRIS AV|    |               BX|     |SKYLINE|\n",
      "| 7-1-2014 6:15:00 AM|      1536 CROSBY AV|    |               BX|     |SKYLINE|\n",
      "| 7-1-2014 8:40:00 AM|       3260 PERRY AV|    |               BX|     |SKYLINE|\n",
      "|7-1-2014 10:40:00 AM|      140 W 140TH ST|    |                M|     |SKYLINE|\n",
      "| 7-1-2014 1:03:00 PM|       17 E 102ND ST|    |                M|     |SKYLINE|\n",
      "| 7-1-2014 3:10:00 PM|       2615 THIRD AV|    |               BX|     |SKYLINE|\n",
      "| 7-1-2014 3:54:00 PM|      1221 JEROME AV|    |               BX|     |SKYLINE|\n",
      "| 7-1-2014 9:20:00 AM|  18718 NASHVILLE BL|    |               QU|     |SKYLINE|\n",
      "|7-1-2014 10:00:00 AM|22620 FRANCIS LEW...|    |               QU|     |SKYLINE|\n",
      "|7-1-2014 12:40:00 PM|        5229 35TH ST|    |      NEW YORK QU|     |SKYLINE|\n",
      "| 7-1-2014 1:40:00 PM|        622 THIRD AV|    |                M|     |SKYLINE|\n",
      "+--------------------+--------------------+----+-----------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixStreetAbbv(df):\n",
    "    df = df.withColumn(\"Street_Address\", F.regexp_replace(F.col('Street_Address'), \" BL$\", \" BLVD\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" AV$\", \" AVE\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" AVENUE$\", \" AVE\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" COURT$\", \" CT\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" STREET$\", \" ST\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" LANE$\", \" LN\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" ROAD$\", \" RD\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" DRIVE$\", \" DR\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" HY$\", \" HWY\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" HY$\", \" HWY\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" PZ$\", \" PLZ\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \" TP$\", \" TPKE\"))\n",
    "    \n",
    "    return df\n",
    "df = fixStreetAbbv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixTheNonNYAddress(a, b):\n",
    "    if b[-2:] == 'NJ' or b[-2:] == 'CT' or b[-2:] == 'LI' or b[-2:] == 'PA':\n",
    "        a =  a + \" \" +b[:-2]\n",
    "        \n",
    "    return a\n",
    "ny_udf = F.udf(fixTheNonNYAddress, T.StringType())\n",
    "df = df.withColumn('Street_Address',ny_udf('Street_Address', 'City_State'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateState(df):\n",
    "    df = df.withColumn('City', F.substring(F.col('City_State'), -2, 2))\n",
    "    return df\n",
    "df = separateState(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = removeTrailingAndLeadingSpaces(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineState(df):\n",
    "    df = df.withColumn('State', F.when((F.col('City') == ('M')) | (F.col('City') == ('QU')) | (F.col('City') == ('BX')) | (F.col('City') == ('CA')) | (F.col('City') == ('ST')) | (F.col('City') == ('WE')) | (F.col('City') == ('BK')) | (F.col('City') == ('FK')) | (F.col('City') == ('AG')), 'NEW YORK').otherwise(F.col('State')))\n",
    "    df = df.withColumn('State', F.when(F.col('City') == ('PA'), 'PENNSYLVANIA').otherwise(F.col('State')))\n",
    "    df = df.withColumn('State', F.when(F.col('City') == ('CT'), 'CONNECTICUT').otherwise(F.col('State')))\n",
    "    df = df.withColumn('State', F.when(F.col('City') == ('LI'), 'LONG ISLAND').otherwise(F.col('State')))\n",
    "    df = df.withColumn('State', F.when((F.col('City') == ('NJ')) | (F.col('City') == ('WK')), 'NEW JERSEY').otherwise(F.col('State')))\n",
    "    \n",
    "    return df\n",
    "df = defineState(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cityName(df):\n",
    "    df = df.withColumn('City', F.when(F.col('City') == 'NJ', F.regexp_replace(F.col('City'), \"NJ\", \"\")).otherwise(F.col('City')))\n",
    "    df = df.withColumn('City', F.when(F.col('City') == 'LI', F.regexp_replace(F.col('City'), \"LI\", \"\")).otherwise(F.col('City')))\n",
    "    df = df.withColumn('City', F.when(F.col('City') == 'PA', F.regexp_replace(F.col('City'), \"PA\", \"\")).otherwise(F.col('City')))\n",
    "    df = df.withColumn('City', F.when(F.col('City') == 'CT', F.regexp_replace(F.col('City'), \"CT\", \"\")).otherwise(F.col('City')))\n",
    "    df = df.withColumn('City', F.when(F.col('City') == 'WE', F.regexp_replace(F.col('City'), \"WE\", \"\")).otherwise(F.col('City')))\n",
    "    df = df.withColumn('City', F.regexp_replace(F.col('City'), \"M\", \"MANHATTAN\"))\n",
    "    df = df.withColumn('City', F.regexp_replace(F.col('City'), \"BK\", \"BROOKLYN\"))\n",
    "    df = df.withColumn('City', F.regexp_replace(F.col('City'), \"BX\", \"BRONX\"))\n",
    "    df = df.withColumn('City', F.regexp_replace(F.col('City'), \"QU\", \"QUEENS\"))\n",
    "#     df = df.withColumn('City', F.regexp_replace(F.col('City'), \"NJ\", \"\"))\n",
    "    \n",
    "    \n",
    "    return df\n",
    "df = cityName(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixTheAirportAddress(df):\n",
    "    df = df.withColumn('Street_Address', F.when(F.col('City_State') == 'NWK', '3 BREWSTER').otherwise(F.col('Street_Address')))\n",
    "    df = df.withColumn('Street_Address', F.when(F.col('City_State') == 'JFK', '148-18 134TH ST').otherwise(F.col('Street_Address')))\n",
    "    df = df.withColumn('Street_Address', F.when(F.col('City_State') == 'LAG', '102-05 DITMARS BLVD').otherwise(F.col('Street_Address')))\n",
    "    df = df.withColumn('City_State', F.regexp_replace(F.col('City_State'), \"NWK\", \"NEWARK\"))\n",
    "    \n",
    "    df = df.withColumn('City_State', F.regexp_replace(F.col('City_State'), \"JFK\", \" JAMAICA\"))\n",
    "  \n",
    "    df = df.withColumn('City_State', F.regexp_replace(F.col('City_State'), \"LAG\", \" EAST ELMHURST\"))\n",
    "    \n",
    "    df = df.withColumn('City', F.regexp_replace(F.col('City'), \"FK\", \"JAMAICA\"))\n",
    "    df = df.withColumn('City', F.regexp_replace(F.col('City'), \"WK\", \"NEWARK\"))\n",
    "    df = df.withColumn('City', F.regexp_replace(F.col('City'), \"AG\", \"EAST ELMHURST\"))  \n",
    "    return df\n",
    "df = fixTheAirportAddress(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixTheCityWithNonNYState(df):\n",
    "    df = df.withColumn('City', F.when(F.col('State') == 'NEW JERSEY', '').otherwise(F.col('City')))\n",
    "    df = df.withColumn('City', F.when(F.col('State') == 'CONNECTICUT', '').otherwise(F.col('City')))\n",
    "    df = df.withColumn('City', F.when(F.col('State') == 'PENNSYLVANIA', '').otherwise(F.col('City')))\n",
    "    df = df.withColumn('City', F.when(F.col('State') == 'LONG ISLAND', '').otherwise(F.col('City')))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = removeTrailingAndLeadingSpaces(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fixTheCityWithNonNYState(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(['Datetime', 'Street_Address', 'City', 'State', 'Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+-----------+-------+\n",
      "|            Datetime|      Street_Address|     City|      State| Source|\n",
      "+--------------------+--------------------+---------+-----------+-------+\n",
      "| 7-1-2014 8:27:00 PM|       622 THIRD AVE|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 9:04:00 PM|           E 77TH ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 10:20:00 PM|67 WEST PALISADES...|         | NEW JERSEY|SKYLINE|\n",
      "|7-1-2014 12:28:00 PM|130 MIDDLE NECK R...|         |LONG ISLAND|SKYLINE|\n",
      "| 7-1-2014 4:45:00 PM|        36 E 31ST ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 6:15:00 PM|       120 E 16TH ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 8:55:00 PM|    300 FLATBUSH AVE| BROOKLYN|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 10:00:00 PM|        410 PARK AVE|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 6:00:00 AM|         5 E 22ND ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 5:21:00 AM|     2249 MORRIS AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 6:15:00 AM|     1536 CROSBY AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 8:40:00 AM|      3260 PERRY AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 10:40:00 AM|      140 W 140TH ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 1:03:00 PM|       17 E 102ND ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 3:10:00 PM|      2615 THIRD AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 3:54:00 PM|     1221 JEROME AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 9:20:00 AM|18718 NASHVILLE BLVD|   QUEENS|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 10:00:00 AM|22620 FRANCIS LEW...|   QUEENS|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 12:40:00 PM|        5229 35TH ST|   QUEENS|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 1:40:00 PM|       622 THIRD AVE|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "+--------------------+--------------------+---------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixStreetName(df):\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"FIRST\", \"1ST\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"SECOND\", \"2ND\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"THIRD\", \"3RD\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"FIFTH\", \"5TH\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"SIXTH\", \"6TH\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"SEVENTH\", \"7TH\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"EIGHTH\", \"8TH\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"NINTH\", \"9TH\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"TENTH\", \"10TH\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"ELEVENTH\", \"11TH\"))\n",
    "    df = df.withColumn('Street_Address', F.regexp_replace(F.col('Street_Address'), \"TWELFTH\", \"12TH\"))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fixStreetName(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalizeColulmns(df):\n",
    "    for col in df.columns:\n",
    "        df = df.withColumnRenamed(col, col.upper())\n",
    "    return df\n",
    "\n",
    "df = capitalizeColulmns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = removeTrailingAndLeadingSpaces(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+-----------+-------+\n",
      "|            DATETIME|      STREET_ADDRESS|     CITY|      STATE| SOURCE|\n",
      "+--------------------+--------------------+---------+-----------+-------+\n",
      "| 7-1-2014 8:27:00 PM|         622 3RD AVE|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 9:04:00 PM|           E 77TH ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 10:20:00 PM|67 WEST PALISADES...|         | NEW JERSEY|SKYLINE|\n",
      "|7-1-2014 12:28:00 PM|130 MIDDLE NECK R...|         |LONG ISLAND|SKYLINE|\n",
      "| 7-1-2014 4:45:00 PM|        36 E 31ST ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 6:15:00 PM|       120 E 16TH ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 8:55:00 PM|    300 FLATBUSH AVE| BROOKLYN|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 10:00:00 PM|        410 PARK AVE|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 6:00:00 AM|         5 E 22ND ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 5:21:00 AM|     2249 MORRIS AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 6:15:00 AM|     1536 CROSBY AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 8:40:00 AM|      3260 PERRY AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 10:40:00 AM|      140 W 140TH ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 1:03:00 PM|       17 E 102ND ST|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 3:10:00 PM|        2615 3RD AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 3:54:00 PM|     1221 JEROME AVE|    BRONX|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 9:20:00 AM|18718 NASHVILLE BLVD|   QUEENS|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 10:00:00 AM|22620 FRANCIS LEW...|   QUEENS|   NEW YORK|SKYLINE|\n",
      "|7-1-2014 12:40:00 PM|        5229 35TH ST|   QUEENS|   NEW YORK|SKYLINE|\n",
      "| 7-1-2014 1:40:00 PM|         622 3RD AVE|MANHATTAN|   NEW YORK|SKYLINE|\n",
      "+--------------------+--------------------+---------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.limit(100).write.csv(\"standardizedCSVSkyline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.coalesce(1).limit(100).write.save(path='dial7_complete.csv', format='csv', mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
